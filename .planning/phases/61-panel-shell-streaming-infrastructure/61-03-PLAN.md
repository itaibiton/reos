---
phase: 61-panel-shell-streaming-infrastructure
plan: 03
type: execute
wave: 2
depends_on: ["61-01", "61-02"]
files_modified:
  - src/components/ai/hooks/useAIAssistantChat.ts
  - src/components/ai/AIAssistantPanel.tsx
  - src/components/ai/ChatMessageList.tsx
  - src/components/ai/ChatMessage.tsx
  - src/components/ai/AIChatPanel.tsx
  - messages/en.json
  - messages/he.json
autonomous: true

must_haves:
  truths:
    - "Messages stream token-by-token as the AI responds -- no block-wait followed by full text dump"
    - "Tool results render inline as structured cards (property cards, provider cards) during streaming"
    - "All AI panel UI strings are translated in both English and Hebrew"
    - "On panel open, if last session is >24h old, user sees a fresh welcome state with context from prior session"
    - "Clear memory deletes all threads and resets to welcome state"
  artifacts:
    - path: "src/components/ai/hooks/useAIAssistantChat.ts"
      provides: "Real-time streaming hook using useUIMessages from @convex-dev/agent/react"
      exports: ["useAIAssistantChat"]
    - path: "messages/en.json"
      provides: "English i18n strings for AI assistant panel"
      contains: "aiAssistant"
    - path: "messages/he.json"
      provides: "Hebrew i18n strings for AI assistant panel"
      contains: "aiAssistant"
  key_links:
    - from: "src/components/ai/hooks/useAIAssistantChat.ts"
      to: "convex/ai/streaming.ts"
      via: "useUIMessages subscribing to api.ai.streaming.listMessages"
      pattern: "api\\.ai\\.streaming\\.listMessages"
    - from: "src/components/ai/AIAssistantPanel.tsx"
      to: "src/components/ai/hooks/useAIAssistantChat.ts"
      via: "useAIAssistantChat hook providing messages and sendMessage"
      pattern: "useAIAssistantChat"
    - from: "src/components/ai/ChatMessage.tsx"
      to: "useUIMessages UIMessage type"
      via: "Rendering message.parts (text + toolCall + toolResult)"
      pattern: "parts|UIMessage"
---

<objective>
Wire real-time streaming from the backend to the frontend panel. Create the new useAIAssistantChat hook using @convex-dev/agent/react, update chat components to render streamed UIMessages, and add full i18n support for all panel strings.

Purpose: This plan delivers the token-by-token streaming experience that is the core UX differentiator of the AI assistant. Without this, users see a typing indicator until the full response loads -- with this, they see words appear in real-time.

Output: New `useAIAssistantChat.ts` hook, updated `AIAssistantPanel.tsx` (wired to streaming), updated `ChatMessageList.tsx` and `ChatMessage.tsx` (UIMessage format), i18n strings in `en.json` and `he.json`.
</objective>

<execution_context>
@/Users/Kohelet/.claude/get-shit-done/workflows/execute-plan.md
@/Users/Kohelet/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/research/STACK.md
@.planning/phases/61-panel-shell-streaming-infrastructure/61-01-PLAN.md
@.planning/phases/61-panel-shell-streaming-infrastructure/61-02-PLAN.md
@src/components/ai/hooks/useAIChat.ts
@src/components/ai/AIChatPanel.tsx
@src/components/ai/ChatMessageList.tsx
@src/components/ai/ChatMessage.tsx
@src/components/ai/AIChatInput.tsx
@src/components/ai/hooks/useSmartScroll.ts
@convex/ai/streaming.ts
@convex/ai/threads.ts
@convex/ai/chat.ts
@messages/en.json
@messages/he.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: useAIAssistantChat hook + i18n strings</name>
  <files>
    src/components/ai/hooks/useAIAssistantChat.ts
    messages/en.json
    messages/he.json
  </files>
  <action>
**1. Create `src/components/ai/hooks/useAIAssistantChat.ts`:**

This hook replaces `useAIChat` for the global assistant panel. It uses `useUIMessages` from `@convex-dev/agent/react` for real-time streaming subscriptions instead of action-based polling.

```typescript
"use client";

import { useCallback, useState } from "react";
import { useAction, useMutation, useQuery } from "convex/react";
import { api } from "../../../../convex/_generated/api";
import { useUIMessages } from "@convex-dev/agent/react";
import type { UIMessage } from "@convex-dev/agent/react";
```

**Hook signature and return type:**
```typescript
export function useAIAssistantChat() {
  // Returns:
  return {
    messages: UIMessage[],       // Real-time streamed messages
    isStreaming: boolean,        // Whether AI is currently generating
    isLoading: boolean,          // Initial load state
    error: string | null,        // Error state
    sendMessage: (text: string) => Promise<void>,
    stopGeneration: () => Promise<void>,
    clearMemory: () => Promise<void>,
    loadMore: () => void,        // Pagination for history
    status: string,              // "loading" | "idle" | etc.
  };
}
```

**Implementation details:**

a) Get the current thread (needed for thread ID):
```typescript
const thread = useQuery(api.ai.threads.getThreadForUser);
const agentThreadId = thread?.agentThreadId;
```

b) Subscribe to streaming messages using `useUIMessages`:
```typescript
const {
  results: messages,
  loadMore,
  status,
  isLoading: messagesLoading,
} = useUIMessages(
  api.ai.streaming.listMessages,
  agentThreadId ? { threadId: agentThreadId } : "skip",
  { initialNumItems: 50, stream: true }
);
```

IMPORTANT: The first argument to `useUIMessages` is the query reference from `api.ai.streaming.listMessages` (created in Plan 61-01). The second argument is the query args OR `"skip"` to skip the subscription when no thread exists. The third argument configures pagination and streaming. `stream: true` enables real-time token-by-token updates.

c) The `messages` returned by `useUIMessages` are `UIMessage[]`. Each `UIMessage` has:
- `id: string`
- `role: "user" | "assistant"`
- `parts: UIMessagePart[]` where each part is one of:
  - `{ type: "text", text: string }` -- text content (streamed incrementally)
  - `{ type: "tool-invocation", toolInvocationId: string, toolName: string, args: any, state: "partial-call" | "call" | "result", result?: any }` -- tool calls and results

d) Track streaming state:
```typescript
// Detect streaming: check if last message is from assistant and still being generated
const isStreaming = messages.length > 0 &&
  messages[messages.length - 1].role === "assistant" &&
  status === "streaming";
// Or alternatively, track via local state set during sendMessage
const [isSending, setIsSending] = useState(false);
```

Actually, a simpler approach: the `useUIMessages` hook may include a `isStreaming` or status indicator. Check the return type. If not, detect streaming by checking if the last assistant message has incomplete content (parts still being appended).

For reliability, use a local `isSending` state that is set `true` when `sendMessage` is called and set `false` when the action completes:

```typescript
const [isSending, setIsSending] = useState(false);
const [error, setError] = useState<string | null>(null);
```

e) Send message using the existing action:
```typescript
const sendMessageAction = useAction(api.ai.chat.sendMessage);
const stopGenerationAction = useAction(api.ai.chat.stopGeneration);
const clearMemoryMutation = useMutation(api.ai.threads.clearMemory);

const sendMessage = useCallback(async (text: string) => {
  if (!text.trim()) return;
  setError(null);
  setIsSending(true);
  try {
    await sendMessageAction({ message: text });
  } catch (err) {
    if (err instanceof Error && !err.message.includes("abort")) {
      setError(err instanceof Error ? err.message : "Failed to send message");
    }
  } finally {
    setIsSending(false);
  }
}, [sendMessageAction]);
```

NOTE: Unlike `useAIChat`, we do NOT need optimistic updates or manual refetching. The `useUIMessages` subscription automatically updates in real-time. When `sendMessage` action is called:
1. The action creates the user message in the agent thread
2. The `listUIMessages` query subscription immediately reflects the new user message
3. As the AI streams its response via `streamText` with `saveStreamDeltas: true`, the `syncStreams` part of the query delivers token-by-token updates
4. The `messages` array updates reactively

f) Stop generation:
```typescript
const stopGeneration = useCallback(async () => {
  if (!thread?._id) return;
  try {
    await stopGenerationAction({ threadId: thread._id });
  } catch (err) {
    console.error("Failed to stop generation:", err);
  }
}, [thread?._id, stopGenerationAction]);
```

g) Clear memory:
```typescript
const clearMemory = useCallback(async () => {
  try {
    await clearMemoryMutation({});
  } catch (err) {
    setError(err instanceof Error ? err.message : "Failed to clear memory");
  }
}, [clearMemoryMutation]);
```

h) Computed loading state:
```typescript
const isLoading = thread === undefined || (agentThreadId !== undefined && messagesLoading);
```

**Re-export the UIMessage type for components to use:**
```typescript
export type { UIMessage };
```

**2. Add i18n strings to `messages/en.json`:**

Add a new top-level `"aiAssistant"` key (NOT inside the existing `"ai"` key -- that one is for the old investor-specific AI). Add it after the `"ai"` block:

```json
"aiAssistant": {
  "panelTitle": "AI Assistant",
  "panelDescription": "Your AI-powered real estate assistant",
  "toggle": "AI Assistant",
  "toggleTooltip": "Toggle AI Assistant (Ctrl+J)",
  "toggleTooltipMac": "Toggle AI Assistant (Cmd+J)",
  "fabLabel": "Open AI Assistant",
  "welcome": {
    "title": "Welcome to your AI Assistant",
    "subtitle": "Ask me anything about real estate investing in Israel.",
    "newSession": "Starting a new conversation. I remember key details from our last chat."
  },
  "input": {
    "placeholder": "Type a message...",
    "placeholderMobile": "Message...",
    "send": "Send message",
    "stop": "Stop generating"
  },
  "header": {
    "title": "AI Assistant",
    "clear": "Clear",
    "close": "Close"
  },
  "clearDialog": {
    "title": "Clear conversation?",
    "description": "This will permanently delete all messages and reset the AI's memory. This action cannot be undone.",
    "cancel": "Cancel",
    "confirm": "Clear conversation"
  },
  "errors": {
    "sendFailed": "Failed to send message. Please try again.",
    "connectionLost": "Connection lost. Reconnecting...",
    "generic": "Something went wrong. Please try again."
  },
  "loading": "Loading conversation...",
  "streaming": "AI is thinking..."
}
```

**3. Add i18n strings to `messages/he.json`:**

Add the same structure in Hebrew:

```json
"aiAssistant": {
  "panelTitle": "עוזר AI",
  "panelDescription": "העוזר החכם שלך להשקעות נדל\"ן",
  "toggle": "עוזר AI",
  "toggleTooltip": "פתח/סגור עוזר AI (Ctrl+J)",
  "toggleTooltipMac": "פתח/סגור עוזר AI (Cmd+J)",
  "fabLabel": "פתח עוזר AI",
  "welcome": {
    "title": "ברוכים הבאים לעוזר ה-AI שלך",
    "subtitle": "שאלו אותי כל דבר על השקעות נדל\"ן בישראל.",
    "newSession": "מתחילים שיחה חדשה. אני זוכר פרטים חשובים מהשיחה הקודמת שלנו."
  },
  "input": {
    "placeholder": "הקלידו הודעה...",
    "placeholderMobile": "הודעה...",
    "send": "שלח הודעה",
    "stop": "עצור יצירה"
  },
  "header": {
    "title": "עוזר AI",
    "clear": "נקה",
    "close": "סגור"
  },
  "clearDialog": {
    "title": "לנקות את השיחה?",
    "description": "פעולה זו תמחק לצמיתות את כל ההודעות ותאפס את זיכרון ה-AI. לא ניתן לבטל פעולה זו.",
    "cancel": "ביטול",
    "confirm": "נקה שיחה"
  },
  "errors": {
    "sendFailed": "שליחת ההודעה נכשלה. אנא נסו שוב.",
    "connectionLost": "החיבור נותק. מתחבר מחדש...",
    "generic": "משהו השתבש. אנא נסו שוב."
  },
  "loading": "טוען שיחה...",
  "streaming": "ה-AI חושב..."
}
```

IMPORTANT: These strings go at the same level as the existing `"ai"` key -- as a sibling, not nested inside it. Find the `"ai": { ... }` block in each file and add `"aiAssistant": { ... }` right after it (before `"legal"`).
  </action>
  <verify>
1. `npx tsc --noEmit` -- no TypeScript errors (especially check `useUIMessages` import from `@convex-dev/agent/react`)
2. Verify `messages/en.json` and `messages/he.json` are valid JSON: `node -e "JSON.parse(require('fs').readFileSync('messages/en.json'))"` (no parse errors)
3. Verify `useAIAssistantChat.ts` compiles and exports `useAIAssistantChat` and `UIMessage` type
4. Grep for `"aiAssistant"` in both i18n files -- both should have the full block
  </verify>
  <done>
- `useAIAssistantChat` hook exists using `useUIMessages` for real-time streaming subscriptions
- No optimistic updates or manual refetching -- reactive subscriptions handle everything
- All AI panel UI strings exist in both `en.json` and `he.json` under `"aiAssistant"` key
- The hook re-exports `UIMessage` type for downstream components
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire streaming into panel components + UIMessage rendering</name>
  <files>
    src/components/ai/AIAssistantPanel.tsx
    src/components/ai/AIChatPanel.tsx
    src/components/ai/ChatMessageList.tsx
    src/components/ai/ChatMessage.tsx
  </files>
  <action>
**1. Update `src/components/ai/AIAssistantPanel.tsx`:**

Replace the `AIChatPanel` rendering inside the Sheet/Drawer with a new internal component that uses the streaming hook.

Instead of importing and rendering `<AIChatPanel />`, create an inline `AssistantChatContent` component:

```typescript
import { useAIAssistantChat } from "./hooks/useAIAssistantChat";
import type { UIMessage } from "./hooks/useAIAssistantChat";
```

The content component:
```typescript
function AssistantChatContent() {
  const t = useTranslations("aiAssistant");
  const {
    messages,
    isStreaming,
    isLoading,
    error,
    sendMessage,
    stopGeneration,
    clearMemory,
  } = useAIAssistantChat();

  const [isClearing, setIsClearing] = useState(false);

  const handleClearMemory = async () => {
    setIsClearing(true);
    try {
      await clearMemory();
    } finally {
      setIsClearing(false);
    }
  };

  return (
    <div className="flex flex-col h-full">
      {/* Header */}
      <div className="flex items-center justify-between px-4 py-2 border-b flex-shrink-0">
        <h2 className="font-semibold text-sm">{t("header.title")}</h2>
        <AlertDialog>
          <AlertDialogTrigger asChild>
            <Button
              variant="ghost"
              size="sm"
              disabled={messages.length === 0 || isClearing}
              className="text-muted-foreground hover:text-destructive"
            >
              <HugeiconsIcon icon={Delete02Icon} size={16} className="me-1" />
              {t("header.clear")}
            </Button>
          </AlertDialogTrigger>
          <AlertDialogContent>
            <AlertDialogHeader>
              <AlertDialogTitle>{t("clearDialog.title")}</AlertDialogTitle>
              <AlertDialogDescription>{t("clearDialog.description")}</AlertDialogDescription>
            </AlertDialogHeader>
            <AlertDialogFooter>
              <AlertDialogCancel>{t("clearDialog.cancel")}</AlertDialogCancel>
              <AlertDialogAction
                onClick={handleClearMemory}
                className="bg-destructive text-destructive-foreground hover:bg-destructive/90"
              >
                {t("clearDialog.confirm")}
              </AlertDialogAction>
            </AlertDialogFooter>
          </AlertDialogContent>
        </AlertDialog>
      </div>

      {/* Error display */}
      {error && (
        <div className="px-4 py-2 bg-destructive/10 text-destructive text-sm flex-shrink-0">
          {error}
        </div>
      )}

      {/* Message list -- pass UIMessage[] */}
      <StreamingChatMessageList
        messages={messages}
        isStreaming={isStreaming}
        isLoading={isLoading}
      />

      {/* Input */}
      <AIChatInput
        onSend={sendMessage}
        onStop={stopGeneration}
        isStreaming={isStreaming}
        placeholder={t("input.placeholder")}
      />
    </div>
  );
}
```

Replace `<AIChatPanel className="h-full" />` with `<AssistantChatContent />` in both the Sheet and Drawer variants.

Import the required components: `AlertDialog*` from ui, `HugeiconsIcon`, `Delete02Icon`, `Button`, `AIChatInput`, plus the new streaming message list.

**2. Create `StreamingChatMessageList` in `src/components/ai/ChatMessageList.tsx`:**

Add a NEW export `StreamingChatMessageList` alongside the existing `ChatMessageList` (do NOT remove or modify the existing one -- it is still used by the investor summary page's embedded `AIChatPanel`).

```typescript
import type { UIMessage } from "./hooks/useAIAssistantChat";

interface StreamingChatMessageListProps {
  messages: UIMessage[];
  isStreaming: boolean;
  isLoading?: boolean;
}

export function StreamingChatMessageList({
  messages,
  isStreaming,
  isLoading = false,
}: StreamingChatMessageListProps) {
  const { user } = useUser();
  const t = useTranslations("aiAssistant");
  const { scrollRef, bottomRef, isNearBottom, scrollToBottom } = useSmartScroll(messages);

  return (
    <div className="relative flex-1 overflow-hidden">
      <ScrollArea className="h-full" ref={scrollRef}>
        <div className="flex flex-col gap-4 p-4" role="log" aria-live="polite" aria-relevant="additions">
          {/* Loading state */}
          {isLoading && messages.length === 0 && (
            <div className="text-center text-muted-foreground py-8">
              <p className="text-sm">{t("loading")}</p>
            </div>
          )}

          {/* Welcome message */}
          {!isLoading && messages.length === 0 && !isStreaming && (
            <div className="text-center text-muted-foreground py-8">
              <p className="text-lg font-medium">{t("welcome.title")}</p>
              <p className="text-sm mt-1">{t("welcome.subtitle")}</p>
            </div>
          )}

          {/* Render UIMessages */}
          {messages.map((message) => (
            <StreamingChatMessage
              key={message.id}
              message={message}
              userImage={user?.imageUrl}
              userName={user?.fullName ?? user?.firstName ?? undefined}
            />
          ))}

          {/* Typing indicator when waiting for first token */}
          {isStreaming && messages.length > 0 && messages[messages.length - 1].role === "user" && (
            <div className="flex gap-3">
              <div className="h-8 w-8 rounded-full bg-muted flex items-center justify-center text-xs flex-shrink-0">AI</div>
              <div className="bg-muted rounded-2xl rounded-es-sm"><TypingIndicator /></div>
            </div>
          )}

          <div ref={bottomRef} className="h-px" />
        </div>
      </ScrollArea>

      {!isNearBottom && (
        <Button variant="secondary" size="icon" className="absolute bottom-4 right-4 rounded-full shadow-lg" onClick={scrollToBottom} aria-label="Scroll to bottom">
          <HugeiconsIcon icon={ArrowDown01Icon} size={18} />
        </Button>
      )}
    </div>
  );
}
```

Add the `useTranslations` import at the top of the file.

**3. Create `StreamingChatMessage` in `src/components/ai/ChatMessage.tsx`:**

Add a NEW export `StreamingChatMessage` alongside the existing `ChatMessage`. This renders a `UIMessage` with its `parts` array.

```typescript
import type { UIMessage } from "./hooks/useAIAssistantChat";

interface StreamingChatMessageProps {
  message: UIMessage;
  userImage?: string;
  userName?: string;
}

export const StreamingChatMessage = memo(function StreamingChatMessage({
  message,
  userImage,
  userName,
}: StreamingChatMessageProps) {
  const isUser = message.role === "user";

  // Extract text content from parts
  const textContent = message.parts
    .filter((p): p is { type: "text"; text: string } => p.type === "text")
    .map((p) => p.text)
    .join("");

  // Extract tool invocations from parts
  const toolInvocations = message.parts
    .filter((p): p is any => p.type === "tool-invocation");

  // Check if this message is still streaming (has text but might be incomplete)
  const hasActiveStream = message.parts.some(
    (p) => p.type === "text" && p.text !== undefined
  );

  // ... render with same layout as existing ChatMessage but using parts data
});
```

The rendering structure should match the existing `ChatMessage` layout (avatar, bubble, timestamp) but process `UIMessage.parts` instead of `content` string + `toolCalls` array:

- **Text parts:** Concatenate all `type: "text"` parts into a single string, render with ReactMarkdown (same as current)
- **Tool invocation parts:** For each `type: "tool-invocation"` part:
  - If `state === "call"` or `state === "partial-call"`: Show a loading indicator for that tool
  - If `state === "result"`: Extract `toolName` and `result`, render using existing `PropertyCardRenderer` / `ProviderCardRenderer`

Map tool invocations to the existing `ToolCall` format for card renderers:
```typescript
const toolCallsForRenderers = toolInvocations
  .filter((t) => t.state === "result")
  .map((t) => ({
    toolCallId: t.toolInvocationId,
    toolName: t.toolName,
    args: t.args,
    result: t.result,
  }));

const isToolExecuting = toolInvocations.some((t) => t.state === "call" || t.state === "partial-call");
```

Then pass to existing renderers:
```jsx
<PropertyCardRenderer toolCalls={toolCallsForRenderers} isExecuting={isToolExecuting && !toolCallsForRenderers.some(t => t.toolName === "searchProperties" && t.result)} />
<ProviderCardRenderer toolCalls={toolCallsForRenderers} isExecuting={isToolExecuting && !toolCallsForRenderers.some(t => t.toolName === "searchProviders" && t.result)} />
```

For the streaming cursor: show `<StreamingCursor />` after the text if the message is from the assistant and there are active text parts being streamed (the last text part may still be growing). Use a heuristic: show cursor if `message.role === "assistant"` and this is the LAST message in the list. The parent component should pass an `isLastMessage` prop or the component can check based on position.

Add an `isLastAndStreaming?: boolean` prop to control cursor display:
```typescript
interface StreamingChatMessageProps {
  message: UIMessage;
  userImage?: string;
  userName?: string;
  isLastAndStreaming?: boolean;
}
```

In `StreamingChatMessageList`, pass this:
```jsx
<StreamingChatMessage
  key={message.id}
  message={message}
  isLastAndStreaming={isStreaming && index === messages.length - 1 && message.role === "assistant"}
  userImage={user?.imageUrl}
  userName={user?.fullName ?? user?.firstName ?? undefined}
/>
```

Add `dir="auto"` to the message bubble div for RTL content:
```jsx
<div className={cn("px-4 py-2 text-sm", ...)} dir="auto">
```

**4. Keep `AIChatPanel.tsx` unchanged:**

Do NOT modify `AIChatPanel.tsx`. It continues to work with the old `useAIChat` hook for the investor summary page embedding. The migration happens in Phase 65. The new `AIAssistantPanel.tsx` uses `AssistantChatContent` (which uses `useAIAssistantChat`) instead.

**Important note on UIMessage type compatibility:**

The `UIMessage` type from `@convex-dev/agent/react` may differ slightly from what is documented. If the parts array has a different structure, adapt accordingly. The key properties to check:
- `message.id` (might be `_id` instead)
- `message.role` (should be `"user" | "assistant"`)
- `message.parts` (array of text/tool-invocation parts)
- `message.createdAt` or `_creationTime` for timestamps

If `UIMessage` does not have a `parts` property and instead has `content` (string) + `toolInvocations` (array), adapt the rendering accordingly. The important thing is to use whatever structure `useUIMessages` actually returns. Check types by hovering in your editor or reading the d.ts file in `node_modules/@convex-dev/agent/dist/react`.
  </action>
  <verify>
1. `npx tsc --noEmit` -- no TypeScript errors
2. `npm run build` -- full Next.js build succeeds
3. Open app in browser, open AI panel:
   - Type a message and send
   - Observe tokens appearing incrementally (not all at once after completion)
   - Tool invocations show loading state, then results appear as cards
   - All text strings are from i18n (no hardcoded English in the panel)
4. Switch locale to Hebrew:
   - Panel title, button labels, welcome text, clear dialog all in Hebrew
   - Panel slides from LEFT on RTL
   - Message bubbles respect RTL text direction
5. Test clear memory: click Clear, confirm dialog, messages disappear, welcome state returns
6. Test session persistence: close panel, navigate, reopen -- messages still there
7. Old investor summary page still works (AIChatPanel unchanged, uses useAIChat)
  </verify>
  <done>
- Messages stream token-by-token in real-time via useUIMessages + syncStreams subscription
- Tool results render as structured property/provider cards inline during streaming
- All panel UI strings translated in English and Hebrew
- StreamingChatMessage renders UIMessage.parts (text + tool invocations)
- StreamingChatMessageList handles welcome state, loading, typing indicator, scroll behavior
- Old AIChatPanel component untouched (backward compatible for Phase 65 migration)
- RTL fully supported: panel direction, message bubbles with dir="auto", logical CSS properties
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` and `npm run build` -- zero errors
2. Token-by-token streaming: Send a message, observe text appearing incrementally (not block-wait)
3. Tool cards: Ask for property recommendations, see loading spinner then property cards appear inline
4. i18n: Switch to Hebrew locale -- all panel strings are Hebrew, RTL layout correct
5. Session UX: New session shows welcome, returning session shows existing messages
6. Clear memory: Deletes all threads, shows fresh welcome state
7. Backward compatibility: Investor summary page AI chat still works with old useAIChat
8. Keyboard shortcut still works (Cmd/Ctrl+J) -- from Plan 61-02
9. Panel persists across navigation -- from Plan 61-02
</verification>

<success_criteria>
- Real-time token-by-token streaming visible in the panel (no block-wait pattern)
- Tool results render as property/provider cards inline in the conversation
- Full i18n: all UI strings in English and Hebrew with RTL support
- useAIAssistantChat hook properly subscribes via useUIMessages to api.ai.streaming.listMessages
- Old AIChatPanel unmodified -- no regression on investor summary page
- Clear memory works: deletes all threads, resets to welcome state
</success_criteria>

<output>
After completion, create `.planning/phases/61-panel-shell-streaming-infrastructure/61-03-SUMMARY.md`
</output>
