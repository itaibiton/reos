---
phase: 41-conversational-ai-core
plan: 03
type: execute
wave: 3
depends_on: ["41-02"]
files_modified:
  - src/components/ai/ChatMessageList.tsx
  - src/components/ai/AIChatPanel.tsx
  - src/components/ai/index.ts
autonomous: false

must_haves:
  truths:
    - "User can type message and send to AI assistant"
    - "AI response appears as it generates"
    - "Typing indicator visible while waiting for first token"
    - "Previous messages visible immediately when opening chat"
    - "User can clear chat history"
  artifacts:
    - path: "src/components/ai/ChatMessageList.tsx"
      provides: "Scrollable message list with smart scroll"
      exports: ["ChatMessageList"]
      min_lines: 40
    - path: "src/components/ai/AIChatPanel.tsx"
      provides: "Main chat panel container"
      exports: ["AIChatPanel"]
      min_lines: 80
    - path: "src/components/ai/index.ts"
      provides: "Barrel export for AI components"
      exports: ["AIChatPanel", "ChatMessage", "AIChatInput"]
  key_links:
    - from: "src/components/ai/AIChatPanel.tsx"
      to: "useAIChat hook"
      via: "hook import and usage"
      pattern: "useAIChat\\(\\)"
    - from: "src/components/ai/ChatMessageList.tsx"
      to: "ChatMessage component"
      via: "message rendering loop"
      pattern: "messages\\.map.*ChatMessage"
    - from: "src/components/ai/AIChatPanel.tsx"
      to: "api.ai.chat.sendMessage"
      via: "useAIChat.sendMessage"
      pattern: "sendMessage\\("

user_setup: []
---

<objective>
Assemble the complete AI chat panel by composing the components from Plan 02 with the hooks from Plan 01.

Purpose: Create the final user-facing chat interface that can be embedded in pages. This completes the Phase 41 requirements for basic chat with streaming responses.

Output: AIChatPanel component ready for integration, with clear memory functionality and proper message display.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/41-conversational-ai-core/41-CONTEXT.md
@.planning/phases/41-conversational-ai-core/41-RESEARCH.md
@.planning/phases/41-conversational-ai-core/41-01-SUMMARY.md
@.planning/phases/41-conversational-ai-core/41-02-SUMMARY.md

# Components from Plan 02
@src/components/ai/ChatMessage.tsx
@src/components/ai/TypingIndicator.tsx
@src/components/ai/AIChatInput.tsx

# Hooks from Plan 01
@src/components/ai/hooks/useAIChat.ts
@src/components/ai/hooks/useSmartScroll.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ChatMessageList component</name>
  <files>src/components/ai/ChatMessageList.tsx</files>
  <action>
Create the message list component that renders messages with smart scroll behavior.

**File: src/components/ai/ChatMessageList.tsx**

```typescript
"use client";

import { useUser } from "@clerk/nextjs";
import { ChatMessage } from "./ChatMessage";
import { TypingIndicator } from "./TypingIndicator";
import { useSmartScroll } from "./hooks/useSmartScroll";
import { ScrollArea } from "@/components/ui/scroll-area";
import { Button } from "@/components/ui/button";
import { HugeiconsIcon } from "@hugeicons/react";
import { ArrowDown01Icon } from "@hugeicons/core-free-icons";

interface Message {
  _id: string;
  role: "user" | "assistant";
  content: string;
  _creationTime: number;
}

interface ChatMessageListProps {
  messages: Message[];
  isStreaming: boolean;
  isLoading?: boolean;
}

export function ChatMessageList({ messages, isStreaming, isLoading = false }: ChatMessageListProps) {
  const { user } = useUser();
  const { scrollRef, bottomRef, isNearBottom, scrollToBottom } = useSmartScroll(messages);

  // Get the last message to check if it's still streaming
  const lastMessage = messages[messages.length - 1];
  const isLastMessageStreaming = isStreaming && lastMessage?.role === "assistant";

  return (
    <div className="relative flex-1 overflow-hidden">
      <ScrollArea className="h-full" ref={scrollRef}>
        <div
          className="flex flex-col gap-4 p-4"
          role="log"
          aria-live="polite"
          aria-relevant="additions"
        >
          {/* Loading state */}
          {isLoading && messages.length === 0 && (
            <div className="text-center text-muted-foreground py-8">
              <p className="text-sm">Loading conversation...</p>
            </div>
          )}

          {/* Welcome message if no messages and not loading */}
          {!isLoading && messages.length === 0 && !isStreaming && (
            <div className="text-center text-muted-foreground py-8">
              <p className="text-lg font-medium">Welcome to your AI Assistant</p>
              <p className="text-sm mt-1">
                Ask me anything about real estate investing in Israel.
              </p>
            </div>
          )}

          {/* Message list - shows immediately when available */}
          {messages.map((message, index) => (
            <ChatMessage
              key={message._id}
              role={message.role}
              content={message.content}
              timestamp={message._creationTime}
              isStreaming={isLastMessageStreaming && index === messages.length - 1}
              userImage={user?.imageUrl}
              userName={user?.fullName ?? user?.firstName ?? undefined}
            />
          ))}

          {/* Typing indicator when waiting for AI response */}
          {isStreaming && (!lastMessage || lastMessage.role === "user") && (
            <div className="flex gap-3">
              <div className="h-8 w-8 rounded-full bg-muted flex items-center justify-center text-xs flex-shrink-0">
                AI
              </div>
              <div className="bg-muted rounded-2xl rounded-es-sm">
                <TypingIndicator />
              </div>
            </div>
          )}

          {/* Scroll anchor */}
          <div ref={bottomRef} className="h-px" />
        </div>
      </ScrollArea>

      {/* Scroll to bottom button (shown when not near bottom) */}
      {!isNearBottom && (
        <Button
          variant="secondary"
          size="icon"
          className="absolute bottom-4 right-4 rounded-full shadow-lg"
          onClick={scrollToBottom}
          aria-label="Scroll to bottom"
        >
          <HugeiconsIcon icon={ArrowDown01Icon} size={18} />
        </Button>
      )}
    </div>
  );
}
```

Key features:
- Uses useSmartScroll hook for auto-scroll behavior
- Shows loading state while messages are being fetched
- Shows welcome message when no messages exist (and not loading)
- Messages load immediately when available (no deferred loading)
- Shows TypingIndicator while waiting for first AI token
- Shows StreamingCursor on the last AI message during streaming
- Scroll-to-bottom button appears when user scrolls up
- Accessible with role="log" and aria-live for screen readers
- Uses Clerk's useUser hook to get user avatar/name
  </action>
  <verify>
Run `npx tsc --noEmit` - no type errors.
Verify the Message interface matches what useAIChat returns.
  </verify>
  <done>
ChatMessageList renders messages with smart scroll, loading state, and typing indicator.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create AIChatPanel main container</name>
  <files>src/components/ai/AIChatPanel.tsx</files>
  <action>
Create the main chat panel that composes all components together.

**File: src/components/ai/AIChatPanel.tsx**

```typescript
"use client";

import { useState } from "react";
import { useAIChat } from "./hooks/useAIChat";
import { ChatMessageList } from "./ChatMessageList";
import { AIChatInput } from "./AIChatInput";
import { Button } from "@/components/ui/button";
import {
  AlertDialog,
  AlertDialogAction,
  AlertDialogCancel,
  AlertDialogContent,
  AlertDialogDescription,
  AlertDialogFooter,
  AlertDialogHeader,
  AlertDialogTitle,
  AlertDialogTrigger,
} from "@/components/ui/alert-dialog";
import { HugeiconsIcon } from "@hugeicons/react";
import { Delete02Icon } from "@hugeicons/core-free-icons";
import { cn } from "@/lib/utils";

interface AIChatPanelProps {
  className?: string;
}

export function AIChatPanel({ className }: AIChatPanelProps) {
  const {
    messages,
    isStreaming,
    isLoading,
    error,
    sendMessage,
    stopGeneration,
    clearMemory,
  } = useAIChat();

  const [isClearing, setIsClearing] = useState(false);

  const handleClearMemory = async () => {
    setIsClearing(true);
    try {
      await clearMemory();
    } finally {
      setIsClearing(false);
    }
  };

  return (
    <div className={cn("flex flex-col h-full", className)}>
      {/* Header with clear button */}
      <div className="flex items-center justify-between px-4 py-2 border-b flex-shrink-0">
        <h2 className="font-semibold text-sm">AI Assistant</h2>

        {/* Clear memory with confirmation */}
        <AlertDialog>
          <AlertDialogTrigger asChild>
            <Button
              variant="ghost"
              size="sm"
              disabled={messages.length === 0 || isClearing}
              className="text-muted-foreground hover:text-destructive"
            >
              <HugeiconsIcon icon={Delete02Icon} size={16} className="me-1" />
              Clear
            </Button>
          </AlertDialogTrigger>
          <AlertDialogContent>
            <AlertDialogHeader>
              <AlertDialogTitle>Clear conversation?</AlertDialogTitle>
              <AlertDialogDescription>
                This will permanently delete all messages and reset the AI&apos;s memory.
                This action cannot be undone.
              </AlertDialogDescription>
            </AlertDialogHeader>
            <AlertDialogFooter>
              <AlertDialogCancel>Cancel</AlertDialogCancel>
              <AlertDialogAction
                onClick={handleClearMemory}
                className="bg-destructive text-destructive-foreground hover:bg-destructive/90"
              >
                Clear conversation
              </AlertDialogAction>
            </AlertDialogFooter>
          </AlertDialogContent>
        </AlertDialog>
      </div>

      {/* Error display */}
      {error && (
        <div className="px-4 py-2 bg-destructive/10 text-destructive text-sm flex-shrink-0">
          {error}
        </div>
      )}

      {/* Message list */}
      <ChatMessageList
        messages={messages}
        isStreaming={isStreaming}
        isLoading={isLoading}
      />

      {/* Input */}
      <AIChatInput
        onSend={sendMessage}
        onStop={stopGeneration}
        isStreaming={isStreaming}
        disabled={false}
      />
    </div>
  );
}
```

Key features:
- Composes ChatMessageList and AIChatInput
- Header with "AI Assistant" title and Clear button
- Clear memory confirmation dialog (per CONTEXT.md decision)
- Error display for failed messages
- Passes isLoading to ChatMessageList for loading state
- Full-height flex layout
- Uses useAIChat hook for all state management
  </action>
  <verify>
Run `npx tsc --noEmit` - no type errors.
Verify AlertDialog components are available from shadcn/ui.
  </verify>
  <done>
AIChatPanel provides complete chat interface with header, messages, input, and clear functionality.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create barrel export and verify integration</name>
  <files>src/components/ai/index.ts</files>
  <action>
Create barrel export file for convenient imports.

**File: src/components/ai/index.ts**

```typescript
// AI Chat Components
export { AIChatPanel } from "./AIChatPanel";
export { ChatMessage } from "./ChatMessage";
export { ChatMessageList } from "./ChatMessageList";
export { AIChatInput } from "./AIChatInput";
export { TypingIndicator } from "./TypingIndicator";
export { StreamingCursor } from "./StreamingCursor";

// Hooks
export { useAIChat } from "./hooks/useAIChat";
export { useSmartScroll } from "./hooks/useSmartScroll";
```

This allows clean imports like:
```typescript
import { AIChatPanel } from "@/components/ai";
```
  </action>
  <verify>
Run `npx tsc --noEmit` - no type errors.
All exports resolve correctly.
  </verify>
  <done>
Barrel export created for clean imports of AI chat components.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete AI chat interface with:
- Message display with markdown rendering
- Streaming responses with typing indicator and cursor
- Send/stop message functionality
- Clear memory with confirmation
- Smart auto-scroll behavior
- Previous messages load immediately when opening chat
  </what-built>
  <how-to-verify>
1. Start the dev server: `npm run dev`
2. Navigate to a page where you can test the AIChatPanel (you may need to temporarily add it to an existing page)
3. Send a test message: "Hello, can you tell me about investing in Israel?"
4. Verify:
   - [ ] Typing indicator (bouncing dots) appears while waiting
   - [ ] AI response streams in word by word
   - [ ] Streaming cursor (blinking bar) shows during response
   - [ ] Message bubbles: user right-aligned (blue), AI left-aligned (gray)
   - [ ] Timestamps show relative time (e.g., "just now")
5. Test stop button:
   - Start a long message
   - Click stop button
   - Verify response stops
6. Test clear:
   - Click "Clear" button
   - Confirm in dialog
   - Verify messages are cleared
7. Test smart scroll:
   - Send several messages to create history
   - Scroll up to read old messages
   - Send new message
   - Verify scroll stays in place (doesn't jump to bottom)
   - Click "scroll to bottom" button if visible
8. Test history persistence:
   - Refresh the page
   - Verify previous messages load immediately (not behind a button)
  </how-to-verify>
  <resume-signal>Type "approved" or describe any issues found</resume-signal>
</task>

</tasks>

<verification>
After all tasks complete:
1. `npx tsc --noEmit` passes without errors
2. Files exist:
   - src/components/ai/ChatMessageList.tsx
   - src/components/ai/AIChatPanel.tsx
   - src/components/ai/index.ts
3. Human verification confirms:
   - Streaming works visually
   - Typing indicator shows
   - Clear memory works
   - Smart scroll works
   - Messages load immediately on open
</verification>

<success_criteria>
Phase 41 requirements met:
- CHAT-01: User can send messages to AI assistant (via AIChatInput)
- CHAT-02: AI responds with streaming text (ChatMessage with StreamingCursor)
- CHAT-03: Typing indicator shows while AI is generating (TypingIndicator)
- CHAT-04: Chat history displays previous messages immediately (ChatMessageList with messages from hook)
</success_criteria>

<output>
After completion, create `.planning/phases/41-conversational-ai-core/41-03-SUMMARY.md`
</output>
