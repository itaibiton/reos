---
phase: 41-conversational-ai-core
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - package.json
  - convex/ai/messages.ts
  - src/components/ai/hooks/useAIChat.ts
  - src/components/ai/hooks/useSmartScroll.ts
autonomous: true

must_haves:
  truths:
    - "Frontend can query AI conversation messages in real-time"
    - "Hook manages sending messages and tracking streaming state"
    - "Markdown rendering libraries available for message display"
  artifacts:
    - path: "convex/ai/messages.ts"
      provides: "Public query for listing AI messages"
      exports: ["listMessages"]
    - path: "src/components/ai/hooks/useAIChat.ts"
      provides: "React hook for AI chat state management"
      exports: ["useAIChat"]
    - path: "src/components/ai/hooks/useSmartScroll.ts"
      provides: "Smart auto-scroll hook with Intersection Observer"
      exports: ["useSmartScroll"]
  key_links:
    - from: "convex/ai/messages.ts"
      to: "components.agent.messages"
      via: "internal query to agent component"
      pattern: "ctx\\.runQuery.*listMessagesByThreadId"
    - from: "src/components/ai/hooks/useAIChat.ts"
      to: "api.ai.chat.sendMessage"
      via: "useAction hook"
      pattern: "useAction.*sendMessage"
---

<objective>
Install markdown dependencies and create the data/state foundation for the AI chat interface.

Purpose: Establish the hooks and queries that UI components will consume. Without this foundation, components cannot display messages or send new ones.

Output: React hooks for chat state management, Convex query for message listing, and npm packages for markdown rendering.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/41-conversational-ai-core/41-CONTEXT.md
@.planning/phases/41-conversational-ai-core/41-RESEARCH.md
@.planning/phases/40-ai-infrastructure-foundation/40-03-SUMMARY.md

# Phase 40 infrastructure files
@convex/ai/chat.ts
@convex/ai/threads.ts
@convex/ai/agent.ts
@convex/_generated/api.d.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install markdown rendering dependencies</name>
  <files>package.json</files>
  <action>
Install react-markdown and react-syntax-highlighter for rendering AI responses with code highlighting.

Run:
```bash
npm install react-markdown react-syntax-highlighter
npm install --save-dev @types/react-syntax-highlighter
```

These are standard libraries per RESEARCH.md:
- react-markdown 9.x: Industry standard markdown renderer, safe by default
- react-syntax-highlighter 15.x: Code highlighting with 100+ languages
  </action>
  <verify>
Run `npm ls react-markdown react-syntax-highlighter` - both packages should be listed.
Check package.json contains both dependencies.
  </verify>
  <done>
react-markdown and react-syntax-highlighter installed with TypeScript types.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create public query for listing AI messages</name>
  <files>convex/ai/messages.ts</files>
  <action>
Create a new file `convex/ai/messages.ts` with a public query that wraps the agent's internal message listing.

The query should:
1. Accept no args (uses current user's thread)
2. Get user identity, look up user record
3. Get the user's aiThread to find agentThreadId
4. Call `ctx.runQuery` with `internal.agent.messages.listMessagesByThreadId` using the agentThreadId
5. Return messages in ascending order (oldest first) for display
6. Return messages with fields: role ("user" | "assistant"), content (string), createdAt (number), status
7. Filter to only "success" status messages (not "pending" or "failed")
8. Exclude tool messages for clean display

The internal agent messages query is at `components.agent.messages.listMessagesByThreadId` but we need to access it via the internal API.

Check the actual internal API path in `convex/_generated/api.d.ts` - look for `listMessagesByThreadId` under the agent component's messages namespace.

Reference pattern from chat.ts:
```typescript
const messagesResult = await investorAssistant.listMessages(ctx, {
  threadId: currentThreadId,
  paginationOpts: { numItems: 50, cursor: null },
  excludeToolMessages: true,
  statuses: ["success"],
});
```

For the query, we cannot use `investorAssistant.listMessages` directly in a query (it requires action context). Instead, create a simpler approach:

**Important:** The @convex-dev/agent stores messages in internal tables. For a query to access them, we need to:
1. Look up the agentThreadId from our aiThreads table
2. Use the internal API to query the agent's message table directly

Check if there's a public/internal query exposed for this, or if we need to query the agent's internal `messages` table directly via `ctx.db`.

If the agent component exposes a query via `internal.agent.messages.*`, use that. Otherwise, note that this may require creating an action instead of a query for proper agent access.

**Fallback approach if query access is limited:** Create an action that calls `investorAssistant.listMessages` and returns the results. While actions don't support real-time subscriptions, we can poll or refetch after sending messages.
  </action>
  <verify>
Run `npx convex dev --once` - no type errors.
The query should export `listMessages` function.
  </verify>
  <done>
Public query (or action) available at `api.ai.messages.listMessages` that returns AI conversation messages for the current user.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create useAIChat hook and useSmartScroll hook</name>
  <files>src/components/ai/hooks/useAIChat.ts, src/components/ai/hooks/useSmartScroll.ts</files>
  <action>
Create the hooks directory and two hooks for the AI chat.

**useAIChat.ts:**
```typescript
// Hook for managing AI chat state and actions
// Provides: messages, sendMessage, isStreaming, stopGeneration, clearMemory

import { useQuery, useAction, useMutation } from "convex/react";
import { api } from "@/convex/_generated/api";
import { useState, useCallback } from "react";

export function useAIChat() {
  // Local streaming state (set when sendMessage starts, cleared when it completes)
  const [isStreaming, setIsStreaming] = useState(false);
  const [error, setError] = useState<string | null>(null);

  // Get user's thread
  const thread = useQuery(api.ai.threads.getThreadForUser);

  // Get messages (query or action based on Task 2 implementation)
  const messages = useQuery(api.ai.messages.listMessages);
  // OR if action: const [messages, setMessages] = useState([]); + useEffect with refetch

  // Actions
  const sendMessageAction = useAction(api.ai.chat.sendMessage);
  const stopGenerationAction = useAction(api.ai.chat.stopGeneration);
  const clearMemoryMutation = useMutation(api.ai.threads.clearMemory);

  const sendMessage = useCallback(async (text: string) => {
    if (!text.trim()) return;
    setError(null);
    setIsStreaming(true);

    try {
      await sendMessageAction({ message: text });
    } catch (err) {
      // Handle abort vs real error
      if (err instanceof Error && err.message.includes("abort")) {
        // User stopped generation - not an error
      } else {
        setError(err instanceof Error ? err.message : "Failed to send message");
      }
    } finally {
      setIsStreaming(false);
    }
  }, [sendMessageAction]);

  const stopGeneration = useCallback(async () => {
    if (!thread?._id) return;
    try {
      await stopGenerationAction({ threadId: thread._id });
    } catch (err) {
      console.error("Failed to stop generation:", err);
    }
  }, [thread?._id, stopGenerationAction]);

  const clearMemory = useCallback(async () => {
    try {
      await clearMemoryMutation({});
    } catch (err) {
      setError(err instanceof Error ? err.message : "Failed to clear memory");
    }
  }, [clearMemoryMutation]);

  return {
    messages: messages ?? [],
    isStreaming,
    error,
    threadId: thread?._id,
    sendMessage,
    stopGeneration,
    clearMemory,
  };
}
```

Adjust based on whether Task 2 produces a query or action.

**useSmartScroll.ts:**
```typescript
// Hook for smart auto-scroll behavior
// Only scrolls to bottom if user is near bottom (not interrupting history reading)

import { useEffect, useRef, useState } from "react";

export function useSmartScroll<T>(dependency: T) {
  const scrollRef = useRef<HTMLDivElement>(null);
  const bottomRef = useRef<HTMLDivElement>(null);
  const [isNearBottom, setIsNearBottom] = useState(true);

  // Track if user is near bottom using Intersection Observer
  useEffect(() => {
    if (!bottomRef.current) return;

    const observer = new IntersectionObserver(
      ([entry]) => setIsNearBottom(entry.isIntersecting),
      { threshold: 0.1, rootMargin: "50px" }
    );

    observer.observe(bottomRef.current);
    return () => observer.disconnect();
  }, []);

  // Auto-scroll when dependency changes and user is near bottom
  useEffect(() => {
    if (isNearBottom && scrollRef.current) {
      scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
    }
  }, [dependency, isNearBottom]);

  const scrollToBottom = useCallback(() => {
    if (scrollRef.current) {
      scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
    }
  }, []);

  return { scrollRef, bottomRef, isNearBottom, scrollToBottom };
}
```

Create the directory structure:
```
src/components/ai/
└── hooks/
    ├── useAIChat.ts
    └── useSmartScroll.ts
```
  </action>
  <verify>
Run `npx tsc --noEmit` - no type errors in the new hooks.
Verify imports resolve correctly.
  </verify>
  <done>
useAIChat hook provides messages, sendMessage, isStreaming, stopGeneration, clearMemory.
useSmartScroll hook provides refs and state for smart auto-scroll behavior.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `npm ls react-markdown react-syntax-highlighter` shows both installed
2. `npx convex dev --once` passes without errors
3. `npx tsc --noEmit` passes without errors
4. Files exist:
   - convex/ai/messages.ts
   - src/components/ai/hooks/useAIChat.ts
   - src/components/ai/hooks/useSmartScroll.ts
</verification>

<success_criteria>
- Markdown dependencies installed and available for import
- Public query or action exists for listing AI messages
- useAIChat hook encapsulates all chat state management
- useSmartScroll hook provides Intersection Observer-based scroll detection
- All code passes type checking
</success_criteria>

<output>
After completion, create `.planning/phases/41-conversational-ai-core/41-01-SUMMARY.md`
</output>
