---
phase: 40-ai-infrastructure-foundation
plan: 02
type: execute
wave: 2
depends_on: ["40-01"]
files_modified:
  - convex/ai/context.ts
  - convex/ai/threads.ts
  - convex/ai/summarization.ts
autonomous: true

must_haves:
  truths:
    - "AI can access investor's questionnaire data in context"
    - "Threads persist and can be retrieved by user"
    - "Old messages get summarized when count exceeds threshold"
  artifacts:
    - path: "convex/ai/context.ts"
      provides: "Profile context builder"
      exports: ["buildProfileContext"]
    - path: "convex/ai/threads.ts"
      provides: "Thread management"
      exports: ["getOrCreateThread", "getThreadForUser"]
    - path: "convex/ai/summarization.ts"
      provides: "Message summarization logic"
      exports: ["summarizeOldMessages"]
  key_links:
    - from: "convex/ai/context.ts"
      to: "convex/investorQuestionnaires.ts"
      via: "query import"
      pattern: "investorQuestionnaires"
    - from: "convex/ai/threads.ts"
      to: "convex/schema.ts"
      via: "aiThreads table"
      pattern: "aiThreads"
---

<objective>
Implement the three pillars of AI memory: profile context injection, thread persistence, and summarization for long conversations.

Purpose: Enable the AI to remember conversations across sessions, understand investor profiles, and maintain coherent context in long discussions.
Output: Complete memory infrastructure that future phases (chat UI, recommendations) will use.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/40-ai-infrastructure-foundation/40-RESEARCH.md
@.planning/phases/40-ai-infrastructure-foundation/40-CONTEXT.md
@convex/investorQuestionnaires.ts
@convex/schema.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create profile context builder</name>
  <files>convex/ai/context.ts</files>
  <action>
**Create convex/ai/context.ts:**

```typescript
import { internalQuery } from "../_generated/server";
import { v } from "convex/values";

/**
 * Build a structured profile context string from investor questionnaire data.
 *
 * This context is injected into the AI system prompt, NOT saved as messages.
 * It's rebuilt fresh on each AI call to ensure current data.
 *
 * Per CONTEXT.md decisions:
 * - Profile data is NEVER summarized
 * - Always in context for every AI call
 * - Referenced when relevant, not repeated unnecessarily
 */
export const buildProfileContext = internalQuery({
  args: { userId: v.id("users") },
  handler: async (ctx, { userId }) => {
    // Get the user's questionnaire data
    const questionnaire = await ctx.db
      .query("investorQuestionnaires")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .unique();

    if (!questionnaire) {
      return null;
    }

    // Build structured profile sections
    const sections: string[] = [];

    // Section 1: Background (Phase 11 fields)
    const background: string[] = [];
    if (questionnaire.citizenship) {
      background.push(`Citizenship: ${formatCitizenship(questionnaire.citizenship)}`);
    }
    if (questionnaire.residencyStatus) {
      background.push(`Residency: ${formatResidency(questionnaire.residencyStatus)}`);
    }
    if (questionnaire.experienceLevel) {
      background.push(`Experience: ${formatExperience(questionnaire.experienceLevel)}`);
    }
    if (questionnaire.ownsPropertyInIsrael !== undefined) {
      background.push(`Owns property in Israel: ${questionnaire.ownsPropertyInIsrael ? "Yes" : "No"}`);
    }
    if (questionnaire.investmentType) {
      background.push(`Investment type: ${formatInvestmentType(questionnaire.investmentType)}`);
    }
    if (background.length > 0) {
      sections.push(`### Background\n${background.join("\n")}`);
    }

    // Section 2: Financial Context (Phase 12 fields)
    const financial: string[] = [];
    if (questionnaire.budgetMin !== undefined || questionnaire.budgetMax !== undefined) {
      const min = questionnaire.budgetMin ? `$${(questionnaire.budgetMin / 1000).toFixed(0)}K` : "any";
      const max = questionnaire.budgetMax ? `$${(questionnaire.budgetMax / 1000).toFixed(0)}K` : "any";
      financial.push(`Budget: ${min} - ${max}`);
    }
    if (questionnaire.investmentHorizon) {
      financial.push(`Investment horizon: ${formatHorizon(questionnaire.investmentHorizon)}`);
    }
    if (questionnaire.investmentGoals && questionnaire.investmentGoals.length > 0) {
      financial.push(`Goals: ${questionnaire.investmentGoals.map(formatGoal).join(", ")}`);
    }
    if (questionnaire.yieldPreference) {
      financial.push(`Yield preference: ${formatYieldPref(questionnaire.yieldPreference)}`);
    }
    if (questionnaire.financingApproach) {
      financial.push(`Financing: ${formatFinancing(questionnaire.financingApproach)}`);
    }
    if (financial.length > 0) {
      sections.push(`### Financial Context\n${financial.join("\n")}`);
    }

    // Section 3: Property Preferences (Phase 13 fields)
    const property: string[] = [];
    if (questionnaire.preferredPropertyTypes && questionnaire.preferredPropertyTypes.length > 0) {
      property.push(`Property types: ${questionnaire.preferredPropertyTypes.join(", ")}`);
    }
    if (questionnaire.preferredLocations && questionnaire.preferredLocations.length > 0) {
      property.push(`Preferred locations: ${questionnaire.preferredLocations.join(", ")}`);
    }
    if (questionnaire.minBedrooms !== undefined || questionnaire.maxBedrooms !== undefined) {
      const min = questionnaire.minBedrooms ?? "any";
      const max = questionnaire.maxBedrooms ?? "any";
      property.push(`Bedrooms: ${min} - ${max}`);
    }
    if (questionnaire.minArea !== undefined || questionnaire.maxArea !== undefined) {
      const min = questionnaire.minArea ?? "any";
      const max = questionnaire.maxArea ?? "any";
      property.push(`Area: ${min} - ${max} sqm`);
    }
    if (questionnaire.preferredAmenities && questionnaire.preferredAmenities.length > 0) {
      property.push(`Desired amenities: ${questionnaire.preferredAmenities.join(", ")}`);
    }
    if (questionnaire.locationFlexibility) {
      property.push(`Location flexibility: ${formatFlexibility(questionnaire.locationFlexibility)}`);
    }
    if (property.length > 0) {
      sections.push(`### Property Preferences\n${property.join("\n")}`);
    }

    // Section 4: Timeline & Services (Phase 14 fields)
    const timeline: string[] = [];
    if (questionnaire.purchaseTimeline) {
      timeline.push(`Purchase timeline: ${formatTimeline(questionnaire.purchaseTimeline)}`);
    }
    if (questionnaire.servicesNeeded && questionnaire.servicesNeeded.length > 0) {
      timeline.push(`Services needed: ${questionnaire.servicesNeeded.map(formatService).join(", ")}`);
    }
    if (questionnaire.additionalPreferences) {
      timeline.push(`Additional notes: ${questionnaire.additionalPreferences}`);
    }
    if (timeline.length > 0) {
      sections.push(`### Timeline & Services\n${timeline.join("\n")}`);
    }

    // Return null if no meaningful profile data
    if (sections.length === 0) {
      return null;
    }

    // Build final context
    return `## Investor Profile

${sections.join("\n\n")}

---
Profile data is current as of the investor's last questionnaire update.`;
  },
});

// Formatting helpers
function formatCitizenship(value: string): string {
  const map: Record<string, string> = {
    israeli: "Israeli citizen",
    non_israeli: "Non-Israeli citizen",
  };
  return map[value] ?? value;
}

function formatResidency(value: string): string {
  const map: Record<string, string> = {
    resident: "Israeli resident",
    returning_resident: "Returning resident (Toshav Chozer)",
    non_resident: "Non-resident",
    unsure: "Unsure of status",
  };
  return map[value] ?? value;
}

function formatExperience(value: string): string {
  const map: Record<string, string> = {
    none: "First-time investor",
    some: "Some experience",
    experienced: "Experienced investor",
  };
  return map[value] ?? value;
}

function formatInvestmentType(value: string): string {
  const map: Record<string, string> = {
    residential: "Personal residence",
    investment: "Investment property",
  };
  return map[value] ?? value;
}

function formatHorizon(value: string): string {
  const map: Record<string, string> = {
    short_term: "Short-term (< 2 years)",
    medium_term: "Medium-term (2-5 years)",
    long_term: "Long-term (5+ years)",
  };
  return map[value] ?? value;
}

function formatGoal(value: string): string {
  const map: Record<string, string> = {
    appreciation: "Capital appreciation",
    rental_income: "Rental income",
    diversification: "Portfolio diversification",
    tax_benefits: "Tax benefits",
  };
  return map[value] ?? value;
}

function formatYieldPref(value: string): string {
  const map: Record<string, string> = {
    rental_yield: "Prioritize rental yield",
    appreciation: "Prioritize appreciation",
    balanced: "Balanced approach",
  };
  return map[value] ?? value;
}

function formatFinancing(value: string): string {
  const map: Record<string, string> = {
    cash: "Cash purchase",
    mortgage: "Will need mortgage",
    exploring: "Exploring options",
  };
  return map[value] ?? value;
}

function formatFlexibility(value: string): string {
  const map: Record<string, string> = {
    flexible: "Flexible on location",
    specific: "Specific locations only",
    nearby_cities: "Open to nearby cities",
  };
  return map[value] ?? value;
}

function formatTimeline(value: string): string {
  const map: Record<string, string> = {
    "3_months": "Within 3 months",
    "6_months": "Within 6 months",
    "1_year": "Within 1 year",
    exploring: "Just exploring",
  };
  return map[value] ?? value;
}

function formatService(value: string): string {
  const map: Record<string, string> = {
    broker: "Broker",
    mortgage_advisor: "Mortgage advisor",
    lawyer: "Lawyer",
  };
  return map[value] ?? value;
}
```

This context builder:
- Reads questionnaire data fresh on each call (never stale)
- Formats data for natural reading by AI
- Groups into logical sections
- Returns null if no profile data exists
  </action>
  <verify>
```bash
npx convex dev --once
```
Should compile without type errors.
  </verify>
  <done>convex/ai/context.ts exists with buildProfileContext that formats all questionnaire fields into structured markdown sections</done>
</task>

<task type="auto">
  <name>Task 2: Create thread management</name>
  <files>convex/ai/threads.ts</files>
  <action>
**Create convex/ai/threads.ts:**

```typescript
import { query, mutation, internalMutation } from "../_generated/server";
import { v } from "convex/values";

/**
 * Get the AI thread for the current user, or null if none exists.
 */
export const getThreadForUser = query({
  args: {},
  handler: async (ctx) => {
    const identity = await ctx.auth.getUserIdentity();
    if (!identity) return null;

    const user = await ctx.db
      .query("users")
      .withIndex("by_clerk_id", (q) => q.eq("clerkId", identity.subject))
      .unique();
    if (!user) return null;

    return await ctx.db
      .query("aiThreads")
      .withIndex("by_user", (q) => q.eq("userId", user._id))
      .unique();
  },
});

/**
 * Get or create an AI thread for the current user.
 * Returns the thread ID for use with the agent.
 */
export const getOrCreateThread = mutation({
  args: {},
  handler: async (ctx) => {
    const identity = await ctx.auth.getUserIdentity();
    if (!identity) {
      throw new Error("Not authenticated");
    }

    const user = await ctx.db
      .query("users")
      .withIndex("by_clerk_id", (q) => q.eq("clerkId", identity.subject))
      .unique();
    if (!user) {
      throw new Error("User not found");
    }

    // Check for existing thread
    const existing = await ctx.db
      .query("aiThreads")
      .withIndex("by_user", (q) => q.eq("userId", user._id))
      .unique();

    if (existing) {
      // Update last activity
      await ctx.db.patch(existing._id, {
        lastActivityAt: Date.now(),
        updatedAt: Date.now(),
      });
      return {
        threadId: existing._id,
        agentThreadId: existing.agentThreadId,
        isNew: false,
      };
    }

    // Create new thread
    const now = Date.now();
    const threadId = await ctx.db.insert("aiThreads", {
      userId: user._id,
      lastActivityAt: now,
      createdAt: now,
      updatedAt: now,
    });

    return {
      threadId,
      agentThreadId: undefined,
      isNew: true,
    };
  },
});

/**
 * Update the thread with the agent's internal thread ID.
 * Called after first message creates the agent thread.
 */
export const linkAgentThread = internalMutation({
  args: {
    threadId: v.id("aiThreads"),
    agentThreadId: v.string(),
  },
  handler: async (ctx, { threadId, agentThreadId }) => {
    await ctx.db.patch(threadId, {
      agentThreadId,
      updatedAt: Date.now(),
    });
  },
});

/**
 * Update thread's summary (called by summarization process).
 */
export const updateSummary = internalMutation({
  args: {
    threadId: v.id("aiThreads"),
    summary: v.string(),
    summarizedMessageCount: v.number(),
  },
  handler: async (ctx, { threadId, summary, summarizedMessageCount }) => {
    await ctx.db.patch(threadId, {
      summary,
      summarizedMessageCount,
      updatedAt: Date.now(),
    });
  },
});

/**
 * Clear AI memory for current user (per CONTEXT.md: explicit "clear memory" option).
 */
export const clearMemory = mutation({
  args: {},
  handler: async (ctx) => {
    const identity = await ctx.auth.getUserIdentity();
    if (!identity) {
      throw new Error("Not authenticated");
    }

    const user = await ctx.db
      .query("users")
      .withIndex("by_clerk_id", (q) => q.eq("clerkId", identity.subject))
      .unique();
    if (!user) {
      throw new Error("User not found");
    }

    // Find and delete the thread
    const thread = await ctx.db
      .query("aiThreads")
      .withIndex("by_user", (q) => q.eq("userId", user._id))
      .unique();

    if (thread) {
      await ctx.db.delete(thread._id);
    }

    return { cleared: true };
  },
});
```

This provides:
- Thread lookup for current user
- Thread creation on first AI interaction
- Agent thread linking (internal)
- Summary updates (internal)
- Explicit memory clearing (per CONTEXT.md decision)
  </action>
  <verify>
```bash
npx convex dev --once
```
Should compile without errors.
  </verify>
  <done>convex/ai/threads.ts exists with getOrCreateThread, getThreadForUser, linkAgentThread, updateSummary, and clearMemory functions</done>
</task>

<task type="auto">
  <name>Task 3: Create summarization logic</name>
  <files>convex/ai/summarization.ts</files>
  <action>
**Create convex/ai/summarization.ts:**

```typescript
import { internalAction } from "../_generated/server";
import { internal } from "../_generated/api";
import { v } from "convex/values";
import Anthropic from "@anthropic-ai/sdk";

/**
 * Summarization thresholds (from RESEARCH.md)
 */
const SUMMARIZE_THRESHOLD = 15; // Start summarizing at 15 messages
const KEEP_RECENT = 10; // Always keep last 10 messages verbatim

/**
 * Summarize older messages to maintain context in long conversations.
 *
 * Per CONTEXT.md decisions:
 * - Profile data + explicit decisions are NEVER summarized
 * - Proactive transparency: Let user know when compressing ("I'm focusing on our recent discussion")
 * - Memory gaps: Check memory first before admitting missing info
 *
 * Called after each AI response when message count exceeds threshold.
 */
export const summarizeOldMessages = internalAction({
  args: {
    threadId: v.id("aiThreads"),
    messages: v.array(
      v.object({
        role: v.union(v.literal("user"), v.literal("assistant")),
        content: v.string(),
      })
    ),
  },
  handler: async (ctx, { threadId, messages }) => {
    // Don't summarize if under threshold
    if (messages.length <= SUMMARIZE_THRESHOLD) {
      return { summarized: false };
    }

    // Split messages: older to summarize, recent to keep
    const olderMessages = messages.slice(0, -KEEP_RECENT);
    const recentMessages = messages.slice(-KEEP_RECENT);

    // Skip if nothing to summarize
    if (olderMessages.length === 0) {
      return { summarized: false };
    }

    try {
      // Build conversation text for summarization
      const conversationText = olderMessages
        .map((m) => `${m.role === "user" ? "User" : "Assistant"}: ${m.content}`)
        .join("\n\n");

      // Call Claude to generate summary
      const anthropic = new Anthropic({
        apiKey: process.env.ANTHROPIC_API_KEY,
      });

      const response = await anthropic.messages.create({
        model: "claude-3-haiku-20240307", // Use Haiku for cost-effective summarization
        max_tokens: 500,
        system: `You are summarizing a conversation between an investor and a real estate assistant.

Create a concise summary that captures:
1. Key topics discussed
2. Any specific property/location interests mentioned
3. Important decisions or preferences stated
4. Questions asked and answers given

Important:
- Focus on ACTIONABLE information the assistant needs to remember
- Exclude pleasantries and filler
- Keep it under 300 words
- Use bullet points for clarity`,
        messages: [
          {
            role: "user",
            content: `Summarize this conversation:\n\n${conversationText}`,
          },
        ],
      });

      // Extract summary text
      const textBlock = response.content.find((block) => block.type === "text");
      if (!textBlock || textBlock.type !== "text") {
        console.error("No text response from summarization");
        return { summarized: false };
      }

      const summary = textBlock.text;

      // Store summary in thread
      await ctx.runMutation(internal.ai.threads.updateSummary, {
        threadId,
        summary,
        summarizedMessageCount: olderMessages.length,
      });

      return {
        summarized: true,
        olderCount: olderMessages.length,
        recentCount: recentMessages.length,
      };
    } catch (error) {
      console.error("Error summarizing messages:", error);
      return { summarized: false, error: String(error) };
    }
  },
});

/**
 * Build context messages array with summary + recent messages.
 * Used by the agent when preparing context for AI calls.
 */
export function buildContextMessages(
  summary: string | undefined,
  recentMessages: Array<{ role: "user" | "assistant"; content: string }>
): Array<{ role: "user" | "assistant" | "system"; content: string }> {
  const messages: Array<{ role: "user" | "assistant" | "system"; content: string }> = [];

  // Add summary as system context if exists
  if (summary) {
    messages.push({
      role: "system",
      content: `## Previous Conversation Summary\n\n${summary}\n\n---\nNote: I'm focusing on our recent discussion. The above summarizes our earlier conversation.`,
    });
  }

  // Add recent messages
  messages.push(...recentMessages);

  return messages;
}

/**
 * Check if summarization is needed based on message count.
 */
export function shouldSummarize(messageCount: number): boolean {
  return messageCount > SUMMARIZE_THRESHOLD;
}

/**
 * Export thresholds for use in other modules.
 */
export const THRESHOLDS = {
  SUMMARIZE_THRESHOLD,
  KEEP_RECENT,
};
```

This provides:
- Automatic summarization when messages exceed threshold
- Uses Haiku for cost-effective summarization
- Stores summary in thread record
- Helper to build context with summary + recent messages
- Per CONTEXT.md: Proactive transparency about compression
  </action>
  <verify>
```bash
npx convex dev --once
```
Should compile without errors.
  </verify>
  <done>convex/ai/summarization.ts exists with summarizeOldMessages action, buildContextMessages helper, and THRESHOLDS export</done>
</task>

</tasks>

<verification>
1. All three files exist in convex/ai/
2. `npx convex dev --once` completes without errors
3. context.ts reads from investorQuestionnaires table
4. threads.ts manages aiThreads table
5. summarization.ts implements 15-message threshold with 10-message keep-recent
</verification>

<success_criteria>
- Profile context builder formats all questionnaire sections
- Thread management supports get, create, link, and clear operations
- Summarization triggers at 15 messages, keeps last 10 verbatim
- All internal queries/mutations properly typed
- Convex dev runs without errors
</success_criteria>

<output>
After completion, create `.planning/phases/40-ai-infrastructure-foundation/40-02-SUMMARY.md`
</output>
